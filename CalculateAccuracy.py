""" 
   
   CalculateAccuracy.py - Calculates positional accuracy and completeness

      Uses the Hunter-Goodchild Simple Positional Accuracy as described in

      Completeness is calculated as length of omissions and commissions

      The first step in preparing NHDFlowline data for item level metadata
      generation is copying the NHDFlowline datasets from the test and 
      reference source geodatabases. In the case of the White, Vermont 
      subbasin, the test dataset was the High Resolution (1:24,000 scale)
      NHD and the reference was the Local Resolution (1:4,800 scale) NHD. 
      For the Piceance-Yellow and Upper Suwannee subbasins, the test 
      dataset was the Medium Resolution (1:100,000 scale) NHD and the
      reference was the High Resolution (1:24,000 scale) NHD.
      
      Normally, tests of data quality would be based on test and 
      reference data of similar scales. Since the intent of this thesis
      is to demonstrate the impact the structure of metadata has on the
      communication of data quality, the datasets were selected as a 
      matter of convenience rather than direct applicability. Larger scale
      data provides a convenient, ersatz reference dataset for simulating 
      data quality metrics for a smaller scale dataset.
      
      This script accepts three parameters: 
    
      1. the test dataset
      2. the reference dataset
      3. a tolerance value in map units
      
      The tolerance value used in this thesis corresponds to the National
      Map Accuracy Standard for the test data scale. For the White 
      subbasin, this equates to 12.192m. For the Piceance-Yellow and 
      Upper Suwannee subbasins, this equates to 50.8m.
      
      This script begins by dissolving features based on the ReachCode 
      field. In the NHD, many stream segments can be represented as 
      individual features sharing a common ReachCode. The dissolve 
      operation results in a single feature with a unique ReachCode. The 
      script also converts the FDate field from a DATE type field to an 
      integer representing the four-digit year and adds other fields to 
      store item level metadata:
      
      
      Name	Type	Description
      ---------------------------------------------
      Match_Type	Text	Flags the feature as a match (M), 
                                omission (O) or commission (C).
      Feature_Length	Double	Total length of the feature.
      Match_Length	Double	Length of the test feature inside the 
                                buffer around the matching reference 
                                feature.  If there is no match the field
                                will be null.
      Accuracy	        Double	The Simple Positional Accuracy of the 
                                feature if there is a matching feature in 
                                the reference dataset. If there is no match
                                the field will be null.
      Omission_Length	Double	Length of the feature if it determined to 
                                be an error omission, otherwise, null.
      Commission_Length	Double	Length of the feature if it determined to 
                                be an error commission, otherwise, null.
      Feature_Date	Long	The FDate field converted to a four-digit year.
      
      The script then calculates the SPA for features that have matching ReachCodes
      in both the test and reference datasets. A buffer is created around the 
      matching features in the reference dataset based the specified tolerance. The
      test dataset is clipped to the buffer. The length of the resulting clips are 
      then stored in the Match_Length field. The SPA is calculated based on the 
      Feature_Length and Match_Length. The Match_Type field is then set to ‘M’ for 
      all matching features.
      
      Once the matching features are handled, errors of omission are handled. The 
      script finds features in the test dataset that are absent from the reference 
      dataset. The Match_Type field for these features is set to ‘O’ for omission 
      and the feature lengths are stored in the Omission_Length field.  Once the 
      errors of omission are handled, errors of commission are processed. The script
      finds features in the reference dataset that are absent from the test dataset.
      The Match_Type field is set to ‘C’ for these features and the lengths are 
      stored in the Commission_Length field.
      
      A final dataset is generated by merging the matches, omissions and commissions
      into a single feature dataset. This dataset only contains processed data. Nulls
      exist in fields only where results are inappropriate. For instance, errors of 
      omission and commission do not have an Accuracy value because there is no match
      between the test and reference datasets.

"""

import sys
import time

start = time.clock()

import arcgisscripting
gp = arcgisscripting.create(9.3)   # Old School
gp.overwriteoutput = 1

#
# ArcGIS 10.0 needs the m/z flags explicitly set to disabled
#
gp.outputmflag = "DISABLED"
gp.outputzflag = "DISABLED"

# Get the script parameters
testFC = sys.argv[1]       # Test feature class
refFC = sys.argv[2]        # Reference feature class
tolerance = sys.argv[3]    # Buffer tolerance for accuracy

testDesc = gp.Describe(testFC)
gp.workspace = testDesc.Path

testPrepped = 'Test_prepped'
refPrepped = 'Ref_prepped'


#
# Prepare data
#

# Convert Feature Date field to just the year in the 
if 'Feature_Date' not in testDesc.Fields:
    gp.AddField(testFC, 'Feature_Date', 'LONG')
    
gp.CalculateField_management(testFC, \
                             'Feature_Date', \
                             '1900 + int([FDate] / 365)', \
                             'VB')


# Dissolve on ReachCode
gp.AddMessage("Dissolving test data on ReachCode.")

if 'ComID' in testDesc.Fields:
    gp.Dissolve_management(testFC, \
                           testPrepped, \
                           'ReachCode', \
                           'ComID MAX;Feature_Date MIN')
else:
    gp.Dissolve_management(testFC, \
                           testPrepped, 
                           'ReachCode', 
                           'Feature_Date MIN')

gp.RepairGeometry(testPrepped)

testDesc = gp.Describe(testPrepped)

# Make sure we don't lose the ComID - some datasets don't have them!
if 'ComID' in testDesc.Fields:
    gp.AddField(testPrepped, 'ComID', 'DOUBLE')
    gp.CalculateField(testPrepped, 'ComID', '[MAX_ComID]')
    gp.DeleteField(testPrepped, 'MAX_ComID')

gp.AddField(testPrepped, 'Feature_Date', 'DOUBLE')
gp.CalculateField(testPrepped, 'Feature_Date', '[MIN_Feature_Date]')
gp.DeleteField(testPrepped, 'MIN_Feature_Date')

#
# Add fields for metadata and calculate lengths
#
gp.AddMessage("Adding fields, calculating lengths in test dataset.")

# Make our fields (if necessary)
if 'Match_Type' not in testDesc.Fields:
    gp.AddField(testPrepped, 'Match_Type', 'TEXT')

# Metadata fields are all the same type
newFields = ['Feature_Length', \
             'Match_Length', \
             'Accuracy', \
             'Omission_Length', \
             'Commission_Length']

for f in newFields:
    if f not in testDesc.Fields:
        gp.AddField(testPrepped, f, 'DOUBLE')

# Calculate lengths - test FC only
gp.CalculateField_management(testPrepped, \
                             'Feature_Length', \
                             'round(float(!SHAPE.length@meters!),2)', \
                             'PYTHON')

# Dissolve on ReachCode
gp.AddMessage("Dissolving reference data on ReachCode.")

#
# Prepare the reference dataset
#
gp.Dissolve_management(refFC, refPrepped, 'ReachCode')

gp.RepairGeometry(refPrepped)
    
refDesc = gp.Describe(refPrepped)

# Make our fields (if necessary)
if 'Match_Type' not in refDesc.Fields:
    gp.AddField(refPrepped, 'Match_Type', 'TEXT')

for f in newFields:
    if f not in refDesc.Fields:
        gp.AddField(refPrepped, f, 'DOUBLE')

# Calculate lengths
gp.CalculateField_management(refPrepped, \
                             'Feature_Length', \
                             'round(float(!SHAPE.length@meters!),2)', \
                             'PYTHON')


#
# Calculate Accuracy
#
gp.AddMessage("Selecting matching features.")

#
# Flag matches, omissions and commissions in test and reference datasets
#
matches = []
testRCs = []
refRCs = []

# First read all the test ReachCodes into a list
cur = gp.SearchCursor(testPrepped)
row = cur.next()

while row:
    rc = row.GetValue("ReachCode")
    testRCs.append(rc)
    row = cur.next()

# Next, pick out the matches and set match type in reference
cur = gp.UpdateCursor(refPrepped)
row = cur.next()

while row:
    rc = row.GetValue("ReachCode")
    if rc in testRCs:
        matches.append(rc)
        row.SetValue("Match_Type", "M")
    else:
        row.SetValue("Match_Type", "O")
    
    cur.UpdateRow(row)
    row = cur.next()


# Finally, do the same for test
cur = gp.UpdateCursor(testPrepped)
row = cur.next()

while row:
    rc = row.GetValue("ReachCode")
    if rc in matches:
        row.SetValue("Match_Type", "M")
    else:
        row.SetValue("Match_Type", "C")
    
    cur.UpdateRow(row)
    row = cur.next()



#
# Find matching features based on ReachCode in test and reference
#
sql = '"Match_Type" = ' + "'M'"
#gp.MakeFeatureLayer(testPrepped, 'test_m', sql)
#gp.CopyFeatures('test_m', 'test_matches')
#gp.MakeFeatureLayer(refPrepped, 'ref_m', sql)
#gp.CopyFeatures('ref_m', 'ref_matches')

gp.MakeFeatureLayer(testPrepped, 'test_matches', sql)
gp.MakeFeatureLayer(refPrepped, 'ref_matches', sql)


#
# Calculate Simple Positional Acccuracy on matching features
#

# Create a buffer around the reference dataset
gp.AddMessage("Buffering reference dataset.")

try:
    gp.Buffer_analysis('ref_matches', 'ref_buffer', str(float(tolerance) * 2) + ' meters', 'FULL', 'ROUND', 'ALL')
except Exception as e:
    print e.message    
    gp.AddMessage('Buffer failed.')

# Clip the test (now in match) to the reference buffer
gp.AddMessage("Clipping matched features to reference buffer.")
gp.Clip_analysis('test_matches', 'ref_buffer', 'test_clips')

# Calculate the length of the the clipped features - this is inside the buffer
gp.CalculateField_management('test_clips', 'Feature_Length', \
                             'round(float(!SHAPE.length@meters!),2)', \
                             'PYTHON')

# Join the original test feature class with the matched clips
gp.AddMessage("Joining matched to clipped features.")
gp.AddJoin('test_matches', 'ReachCode', 'test_clips', 'ReachCode')

# Save the clipped length as the "Error" - bit of of a misnomer
gp.AddMessage("Calculating errors.")
gp.CalculateField_management('test_matches', \
                             'Match_Length', \
                             '[test_clips.Feature_Length]')

gp.RemoveJoin('test_matches', 'test_clips')

try:
    gp.Delete('test_clips')
except:
    gp.AddMessage('Unable to remove temporary file: clips')

# Do the accuracy calculation
gp.AddMessage("Calculating accuracies.")

gp.CalculateField_management('test_matches', 'Accuracy', \
                             'round(float(!Match_Length!) \
                             / float(!Feature_Length!), 2)', \
                             'PYTHON')

#
# Find errors of commission - reachcodes in the Test but not Reference
#
gp.AddMessage("Finding errors of commission")

# Select reachcodes not found in reference dataset
sql = '"Match_Type" <> ' + "'M'"
gp.MakeFeatureLayer(testPrepped, 'commissions', sql)

gp.CalculateField_management('commissions', \
                             'Commission_Length', \
                             '!Feature_Length!', \
                             'PYTHON')


#
# Find errors of ommission - reachcodes in the Reference but not the Test
#
gp.AddMessage("Finding errors of omission")

# Select features in Reference that are not in Test
sql = '"Match_Type" <> ' + "'M'"

# Copy to omission feature set and update calculations
gp.MakeFeatureLayer(refPrepped, 'omissions', sql)

# Save the length of the features as Ommission Length
gp.CalculateField_management('omissions', \
                             'Omission_Length', \
                             '!Feature_Length!', \
                             'PYTHON')


#
# Merge omissions, commissions and matches into a new dataset 'Accuracy_Result'
#
gp.AddMessage("Merging into result dataset.")

vt = gp.createobject("ValueTable")
vt.AddRow('test_matches')
vt.AddRow('commissions')
vt.AddRow('omissions')

gp.Merge(vt, 'Accuracy_Result')

del vt

fm = gp.CreateObject('FieldMappings')
fm.AddTable('Accuracy_Result')

try:
    gp.Delete(testPrepped)
    gp.Delete(refPrepped)
except:
    gp.AddMessage('Unable to remove testPrepped or refPrepped')

count = int(gp.GetCount('Accuracy_Result').GetOutput(0))

elapsed = time.clock() - start
msg = "Processed " + str(count) + " features in " \
    + str(elapsed) + " seconds."

gp.AddMessage(msg)

rate = count / elapsed

msg = "That's a rate of " + str(rate) + " features per second."

gp.AddMessage(msg)

# Pass the resulting dataset back to ArcGIS
gp.SetParameterAsText(3, 'Accuracy_Result')
del gp